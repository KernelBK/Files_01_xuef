http://nga.178.com/read.php?tid=13331166&rand=976

不能带来新的思维方式的语言，是没有必要存在的。

我们不该

4. 追求“小窍门”。

很多编程书喜欢卖弄一些小窍门，让程序显得“短小”。
比如它们会跟你讲 "(i++) - (++i)" 应该得到什么结果; 或者追究运算符的优先级，说这样可以少打括号;
要不就是告诉你“if 后面如果只有一行代码就可以不加花括号”，等等。
殊不知这些小窍门，其实大部分都是程序语言设计的败笔或者历史遗留问题。
它们带来的不是清晰的思路，而是是逻辑的混乱和认知的负担。
比如 C 语言的 ++ 运算符，它的出现是因为 C 语言设计者们当初用的计算机内存小的可怜，
而 "i++" 显然比 "i=i+1" 少 2 个字符，所以他们觉得可以节省一些空间。现在我们再也不缺那点内存，
可是 ++ 运算符带来的混乱和迷惑，却流传了下来。现在最新的一些语言，也喜欢耍这种语法上的小把戏。
如果你追求这些小窍门，往往就抓不住精髓。


我们应该
1. 专注于“精华”和“原理”。
而对基本概念的一知半解，导致了他们看不清那些复杂概念的实质。比如这些概念里面很重要的一个就是递归。
国内很多学生对递归的理解只停留于汉诺塔这样的程序，而对递归的效率也有很大的误解，认为递归没有循环来得高效。
而其实递归比循环表达能力强很多，而且效率几乎一样。有些程序比如解释器，不用递归的话基本没法完成。

2. 实现一个程序语言。

学习使用一个工具的最好的方式就是制造它，所以学习程序语言的最好方式就是实现一个程序语言。
这并不需要一个完整的编译器，而只需要写一些简单的解释器，实现最基本的功能。之后你就会发现，
所有语言的新特性你都大概知道可以如何实现，而不只停留在使用者的水平。实现程序语言最迅速的方式
就是使用一种像 Scheme 这样代码可以被作为数据的语言。它能让你很快的写出新的语言的解释器。


几种常见风格的语言
1. 面向对象语言

事实说明，“面向对象”这整个概念基本是错误的。设计的初衷是让“界面”和“实现”分离，
从而使得下层实现的改动不影响上层的功能。
可是大部分面向对象语言的设计都遵循一个根本错误的原则：“所有的东西都是对象(Everything is an object)。”
以至于所有的函数都必须放在所谓的“对象”里面，从而不能直接被作为参数或者变量传递。
这导致很多时候需要使用繁琐的设计模式(design patterns) 来达到甚至对于 C 语言都直接了当的事情。
而其实“界面”和“实现”的分离，并不需要把所有函数都放进对象里。
另外的一些概念，比如继承，重载，其实带来的问题比它们解决的还要多。

“面向对象方法”的过度使用，已经开始引起对整个业界的负面作用。
很多公司里的程序员喜欢生搬硬套一些不必要的设计模式，其实什么好事情也没干，只是使得程序冗长难懂。
不得不指出，《Design Patterns》这本书，是这很大一部分复杂性的罪魁祸首。
不幸的是，如此肤浅，毫无内容，偷换概念的书籍，居然被很多人捧为经典。


那么如何看待具备高阶函数的面向对象语言，比如 Python，JavaScript，Ruby，Scala？
当然有了高阶函数，你可以直截了当的表示很多东西，而不需要使用设计模式。
但是由于设计模式思想的流毒，一些程序员居然在这些不需要设计模式的语言里也采用繁琐的设计模式，
让人哭笑不得。所以在学习的时候，最好不要用这些语言，以免受到不必要的干扰。
到时候必要的时候再回来使用它们，就可以取其精华，去其糟粕。


2. 低级过程式语言 
那么是否 C 这样的“低级语言”就会好一些呢？其实也不是。很多人推崇 C，因为它可以让人接近“底层”，
也就是接近机器的表示，这样就意味着它速度快。这里其实有三个问题：
	接近“底层”是否对于初学者是好事？
	“速度快的语言”是什么意思？
	接近底层的语言是否一定速度快？
对于第一个问题，答案是否定的。其实编程最重要的思想是高层的语义(semantics)。
语义构成了人关心的问题以及解决它们的算法。而具体的实现(implementation)，比如一个整数用几个字节表示，
虽然还是重要，但却不是至关重要的。如果把实现作为学习的主要目标，就本末倒置了。因为实现是可以改变的，
而它们所表达的本质却不会变。所以很多人发现自己学会的东西，过不了多久就“过时”了。
那就是因为他们学习的不是本质，而只是具体的实现。


3. 高级过程式语言
现在真正理解了程序语言的设计原理以后我才真正的感觉到，原来 Pascal 是比 C 和 C++ 设计更好的语言。
它不但把人从底层细节里解脱出来，没有面向对象的思维枷锁，而且含有函数式语言的一些特征(比如可以嵌套函数定义)。

现在的含有赋值语句的函数式语言，可以被看作是是高级过程式语言的“改良版本”。

4. 函数式语言

函数式语言相对来说是当今最好的设计，因为它们不但让人专注于算法和对问题的解决，
而且没有面向对象语言那些思维的限制。

理智的使用局部变量或者数组的赋值，会使程序更加简单，容易理解，甚至更加高效。

5. 逻辑式语言
学习逻辑式语言最好是从函数式语言开始，在理解了递归，模式匹配等基本的函数式编程技巧
之后再来看 Prolog，就会发现逻辑式编程简单了很多。





!!!!!!从何开始

首先可以从 Scheme 入门，然后学习一些 Haskell (但不是全部)，之后其它的也就触类旁通了。
你并不需要学习它们的所有细枝末节，而只需要学习最精华的部分。
所有剩余的细节，会在实际使用中很容易的被填补上。


从 Scheme(而不是 Haskell)作为入门的第一步，是因为：
Scheme 没有像 Haskell 那样的静态类型系统 (static type system)。并不是说静态类型不好，
但是我不得不说，Haskell 那样的静态类型系统，还远远没有发展到可以让人可以完全的写出符合事物本质
的程序来。比如，一些重要的概念比如 Y combinator，没法用 Haskell 直接写出来。
??????
当然你可以在 Haskell 里面使用作用类似 Y combinator 的东西(比如 fix，或者利用它的 laziness)，
但是这些并不揭示递归的本质，你只是在依靠 Haskell 已经实现的递归来进行递归，而不能实际的体会
到递归是如何产生的。

而用 Scheme，你可以轻松的写出 Y combinator，并且实际的投入使用。

??????
Scheme 不需要 monad。Haskell是一个“纯函数式” (purely functional) 的语言，
所有的“副作用”(side-effect)，比如打印字符到屏幕，都得用一种故作高深的概念叫 monad 实现。
这种概念其实并不是本质的，它所有的功能都可以通过“状态传递” (state passing) 来实现。
通过写状态传递程序，你可以清楚的看到 monad 的本质。可以说 monad 是 Haskell 的一个“设计模式”。
过早的知道这个东西，并不有助于理解函数式程序设计的本质。


那么为什么又要学 Haskell？那是因为 Haskell 含有 Scheme 缺少的一些东西，
并且没有 Scheme 设计上的一些问题。比如：
1. 模式匹配：Scheme 没有一个标准的，自然的模式匹配(pattern matching) 系统，
而 Haskell 的模式匹配是一个优美的实现。
也有些 Scheme 的扩展实现(比如 Racket)具有相当好的模式匹配机制。

2. 类型：Scheme 把所有不是 #f (false)的值都作为 true，这是不对的。
Haskell 里面的 Boolean 就只有两个值：True 和 False。Scheme 程序员声称这样可以写出简洁的代码，
因为 (or x y z) 可以返回一个具体的值，而不只是一个布尔变量。但是就为了在少数情况下可以写出短
一点的代码，是否值得付出如此沉痛的代价？我看到这个设计带来了很多无需有的问题。

3. 宏系统：宏 (macro) 通常被认为是 Lisp 系列语言的一个重要优点。
但是我要指出的是，它们并不是必要的，至少对于初学者是这样。其实如果一个语言的语义设计好了，
你会几乎不需要宏。因为宏的本质是让程序员可以自己修改语言的设计，添加新的构造。
可是宏的主要缺点是，它把改变语言这种极其危险的“权力”给人滥用了。其实只有极少数的人具有改变
一个语言所需的智慧和经验。如果让普通程序员都能使用宏，那么程序将变得非常难以理解。
所以其实一般程序员都不需要学习宏的使用，也不必为略过这个东西而产生负罪感。
等你进步到可以设计自己的程序语言，你自然会明白宏是什么东西。

(注意，这些是我自己的观点，并不代表 Scheme 设计者们的观点。)


过度到面向对象语言
那么如果从函数式语言入门，如何过渡到面向对象语言呢？毕竟大部分的公司用的是面向对象语言。
如果你真的学会了函数式语言，你真的会发现面向对象语言已经易如反掌。
函数式语言的设计比面向对象语言简单和强大很多，而且几乎所有的函数式语言教材(比如 SICP)
都会教你如何实现一个面向对象系统。

你会深刻的看到面向对象的本质以及它存在的问题，所以你会很容易的搞清楚怎么写面向对象的程序，
并且会发现一些窍门来避开它们的局限。你会发现，即使在实际的工作中必须使用面向对象语言，
也可以避免面向对象的思维方式，因为面向对象的思想带来的大部分是混乱和冗余。



# 深入本质和底层
那么是不是完全不需要学习底层呢？当然不是。但是一开头就学习底层硬件，就会被纷繁复杂的硬件
设计蒙蔽头脑，看不清楚本质上简单的原理。

在学会高层的语言之后，可以进行语义学和编译原理的学习。简言之，语义学 (semantics) 就是研究
程序的符号表示如何对机器产生“意义”，通常语义学的学习包含 lambda calculus 和各种解释器的实现。
编译原理 (compilation) 就是研究如何把高级语言翻译成低级的机器指令。

编译原理其实包含了计算机的组成原理，比如二进制的构造和算术，处理器的结构，内存寻址等等。
但是结合了语义学和编译原理来学习这些东西，会事半功倍。因为你会直观的看到为什么现在的计算机
系统会设计成这个样子：为什么处理器里面有寄存器(register)，为什么需要堆栈(stack)，为什么需要堆(heap)，
它们的本质是什么。

这些甚至是很多硬件设计者都不明白的问题，所以它们的硬件里经常含有一些没必要的东西。
因为他们不理解语义，所以经常不明白他们的硬件到底需要哪些部件和指令。但是从高层语义来解释它们，
就会揭示出它们的本质，从而可以让你明白如何设计出更加优雅和高效的硬件。

这就是为什么一些程序语言专家后来也开始设计硬件。





